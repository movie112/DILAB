{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_ch2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5POYCCnXnz3aWmbAD4g1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/NLP_pytorch/NLP_ch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uOmxgMK5HcY"
      },
      "source": [
        "# 파이토치로 배우는 자연어 처리: ch2\n",
        "## 2. NLP 기술 빠르게 훑어보기   \n",
        "2.1 말뭉치, 토큰, 타입   \n",
        "2.2 유니그램, 바이그램, 트라이그램,,, n-그램   \n",
        "2.3 포제어와 어간   \n",
        "2.4 문장과 문서 분류하기   \n",
        "2.5 단어 분류하기: 품사 태깅   \n",
        "2.6 청크 나누기와 개체명 인식   \n",
        "2.7 문장구조   \n",
        "2.8 단어 의미와 의미론\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adjJMf8ncgEb"
      },
      "source": [
        "\n",
        "## 2.1 말뭉치, 토큰, 타입\n",
        "- 모든 NLP 작업은 `말뭉치(cprpus)`라 부르는 텍스트 데이터에서 시작\n",
        "  - 말뭉치는 원시 텍스트(ASCII, UTF-8)와 메타데이터를 포함\n",
        "- 원시 텍스트\n",
        "  - 문자(바이트) 시퀀스지만 일반적으로 문자를 __토큰__이라는 연속된 단위로 묶었을 때 유용\n",
        "  - 영어에서 토큰은 공백 문자나 구두점으로 구분되는 단어와 숫자에 해당\n",
        "- 메타 데이터\n",
        "  - 식별자, 레이블, 타임스탬프 등 텍스트와 관련된 어떤 부가 정보도 될 수 있다.\n",
        "  - 메타 데이터가 붙은 텍스트를 __샘플__, __데이터 포인트__ 라고 부름\n",
        "  - 샘플의 모음인 말뭉치는 __데이터셋__이라고 부름\n",
        "\n",
        "- 토큰화: 텍스트를 토큰으로 나누는 과정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otcb-Mcc72_-"
      },
      "source": [
        "- 텍스트 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1hHN9mG5Bnx",
        "outputId": "323240e5-20f1-45c6-c90d-79e070df7123"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "text = \"Mary, don't slap the green witch\"\n",
        "print([str(token) for token in nlp(text.lower())])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mary', ',', 'do', \"n't\", 'slap', 'the', 'green', 'witch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0Huui2Z8S5u",
        "outputId": "81a31eee-2e0c-4812-f68b-f6edfeeb66a8"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet =u\"Snow White and the Seven Degrees #MakeAMovieCold @ midnight:-)\"\n",
        "tokenizer = TweetTokenizer()\n",
        "print(tokenizer.tokenize(tweet.lower()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['snow', 'white', 'and', 'the', 'seven', 'degrees', '#makeamoviecold', '@', 'midnight', ':-)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_hdYxHH95ru"
      },
      "source": [
        "- `타입`: 말뭉치에 등장하는 고유한 토큰\n",
        "  - 말뭉치에 있는 모든 타입의 집합이 어휘.\n",
        "  - 단어는 내용어(content words), 불용어(stopword)로 구분\n",
        "  - 관사와 전치사 같은 불용어는 대부분 내용어를 보충하는 문법적인 용도로 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_77xPtbH-Srm"
      },
      "source": [
        "## 2,2 유니그램, 바이그램, 트라이그램,,,n-그램\n",
        "n-그램: 텍스트에 있는 고정길이(n)의 연속된 코튼 시퀀스   \n",
        "바이그램: 토큰 2개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3J0eX8T-jp9",
        "outputId": "ec3d531e-9cbb-4d39-8320-2213a6cc60ad"
      },
      "source": [
        "def n_grams(test, n):\n",
        "  '''\n",
        "  tokes tokens or test, returns a list of n-grams\n",
        "  '''\n",
        "  return [test[i:i+n] for i in range(len(test)-n+1)]\n",
        "\n",
        "cleaned = ['mary', ',', \"n't\", 'slap', 'green', 'witch', '.']\n",
        "print(n_grams(cleaned, 3))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['mary', ',', \"n't\"], [',', \"n't\", 'slap'], [\"n't\", 'slap', 'green'], ['slap', 'green', 'witch'], ['green', 'witch', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqq0IvwI_D4G"
      },
      "source": [
        "부분단어(subword) 자체가 융용한 정보를 전달한다면 문자 n-그램을 생성할 수 있다. 예를들어 'methanol'의 접미사 '-ol'은 알코올 종류를 나타냄 유기 화합물 이름을 구분하는 작업에서는 n-그램으로 찾은 부분 단어의 정보가 유용할 것. 이런 경우 같은 코드를 재사용할 수 있지만 모든 문자의 n-그램을 토큰 하나로 취급"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKc_Ap7G_fZW"
      },
      "source": [
        "## 2.3 표제어와 어간\n",
        "표제어(lemma): 단어의 기본형"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaAsgpWVBSlt",
        "outputId": "76f9778b-3995-46f7-d4f0-b67826dc2284"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "doc = nlp(\"he was running late\")\n",
        "for token in doc:\n",
        "  print('{}-->{}'.format(token, token.lemma_))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "he-->-PRON-\n",
            "was-->be\n",
            "running-->run\n",
            "late-->late\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8H39JREBm5V"
      },
      "source": [
        "어간 추출:(stemming) 표제어 추출 대신 사용하는 축소기법\n",
        "- 수동으로 만든 규칙을 사용해 단어의 끝을 잘라 어간(stem)이라는 공통 형태로 축소\n",
        "- Porter와 Snowball 어간 추출기가 유명\n",
        "\n",
        "## 2.4 문장과 문서 분류하기\n",
        "- TF, TF-IDF 표현이 긴 텍스트 뭉치를 문류하는 데 유용\n",
        "\n",
        "## 2.5 단어 분류하기: 품사 태깅\n",
        "문서에 레이블을 할당하는 개념을 단어나 토큰으로 확장할 수 있다. 단어 분류 작업의 예로 품사(part of speech(POS)), 태깅(tagging)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx-pvuDGCp82",
        "outputId": "f307bd51-252a-4cb3-901f-53e9164b3828"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "doc = nlp(u\"Mary slapped the green witch.\")\n",
        "for token in doc:\n",
        "  print('{} - {}'.format(token, token.pos_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mary - PROPN\n",
            "slapped - VERB\n",
            "the - DET\n",
            "green - ADJ\n",
            "witch - NOUN\n",
            ". - PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8b97QwEC_7O"
      },
      "source": [
        "## 2.6 청크 나누기와 개체명 인식\n",
        "종종 연속된 여러 토큰으로 구분되는 텍스트 구에 레이블을 할당해야 함   \n",
        "example) \"Mary flapped the green witch.\"\n",
        "- 명사구(NP), 동사구(VP)를 구별 필요: [NP Mary] [VP slapped] [the green witch]\n",
        "- 이를 청크 나누기(chunking) 또는 부분 구문 분석(shallow parsing)\n",
        "- 목적: 명사, 동사 같은 문법 요소로 구성된 고차원의 단위를 유도해 내는 것\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpZV_-AoFeTW",
        "outputId": "365172d4-1d10-4a88-9b6d-2d1e5d0ea933"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "doc = nlp(u\"Mary slapped the green witch.\")\n",
        "for chunk in doc.noun_chunks:\n",
        "  print('{} - {}'.format(chunk, chunk.label_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mary - NP\n",
            "the green witch - NP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xliUsjLF8c1"
      },
      "source": [
        "- 개체명(named entity): 실제 세상의 개념을 의미하는 문자열"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxuAr9sbGGI1"
      },
      "source": [
        "## 문장 구조\n",
        "구문 분석(parsaing): 구 사이의 관계 파악   \n",
        "- 구성 구문 분석\n",
        "- 의존 구문 분석\n",
        "\n",
        "## 단어 의미와 의미론\n",
        "- 의미(sense): 단어가 나타내는 각각의 뜻"
      ]
    }
  ]
}
