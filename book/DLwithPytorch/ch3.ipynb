{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dlwithtorch_ch3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VsUYLWoMjehISxM9T6fSmKbEXJbZ3D34",
      "authorship_tag": "ABX9TyMvJs43X2F3IZj1cSPTJfyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/DLwithPytorch/ch3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9szKKbAQL6v7"
      },
      "source": [
        "# 신경망 더 깊이 알아보기\n",
        "  - 신경망의 다양한 구성요소\n",
        "  - 비선형 활성화(activations)\n",
        "  - 심층 학습을 이용한 이미지 분류\n",
        "<br/>\n",
        "\n",
        "#### 딥러닝 알고리즘 훈련단계(review)\n",
        "> 1. 데이터 파이프라인 구축하기\n",
        "> 2. 네트워크 아키텍처 구축하기\n",
        "> 3. 손실 함수를 이용하여 아키텍처 평가\n",
        "> 4. 최적화 알고리즘을 이용하여 가중치들 최적화\n",
        "\n",
        "- 단순한 선형 모델로 구성된 네트워크는 컴퓨터 비전 및 자연어 처리와 같은 여러 분야의 복잡한 문제를 해결하는데 필요한 아키텍처를 구축할 때는 매우 복잡\n",
        "- 파이토치, 텐서플로우 같은 딥러닝 프레임위크는 이러한 복잡성을 추상화하는 더 높은 수준의 기능을 제공\n",
        "  - 레이어(layer):    \n",
        "    - 데이터를 입력받고 변환을 적용하여 데이터를 출력\n",
        "    - 각 layer는 고유한 parameter(가중치)를 가진다.\n",
        "\n",
        "---\n",
        "#### Layers : Fundamental blocks of Neural Network\n",
        "- 선형 레이어: y = w * x + b\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H-SxyB1E1A3"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byKgI0OvbcHP",
        "outputId": "d2b705b7-4ef6-40be-b10d-08eb22b8a0c7"
      },
      "source": [
        "# linear_layer 함수는 크기 5의 tensor를 받아서 선형변환을 한 후 크기 3의 tensor 출력\n",
        "linear_layer = Linear(in_features=5,out_features=3,bias=True)\n",
        "\n",
        "inp = Variable(torch.randn(1,5))\n",
        "linear_layer(inp)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8051, 0.7230, 0.4042]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItF1P7HLcpbA",
        "outputId": "7f7a3b6e-0e2c-4254-d2ca-012cfb139a2b"
      },
      "source": [
        "# .weight, bias로 레이어의 훈련 가능한 poarameter에 접근 가능\n",
        "linear_layer.weight"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.3886,  0.3273,  0.0957,  0.4225, -0.1291],\n",
              "        [ 0.0211,  0.1651,  0.0130, -0.2560,  0.2588],\n",
              "        [-0.3429,  0.1056, -0.3616,  0.2794, -0.2087]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or10_voBcpnW",
        "outputId": "bee43308-7c5b-41e6-e0cc-5e25fdd7c819"
      },
      "source": [
        "linear_layer.bias"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0997,  0.3207,  0.3656], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2XNd2Cc8P_"
      },
      "source": [
        "# layer의 output을 다른 layer로 전달\n",
        "linear_layer = Linear(5,3)\n",
        "linear_layer_2 = Linear(3,2)\n",
        "linear_layer_2(linear_layer(inp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPQ1dCGsL4Yj"
      },
      "source": [
        "---\n",
        "## 비선형 활성화\n",
        " - 단순히 다중 (선형)레이어를 쌓는 것 만으로는 알고리즘이 어떤 새로운 것을 학습하는데 도움이 되지 않는다.\n",
        " - 비선형 함수: 수학적 변환 ex) igmoid, Tanh, ReLU, Leaky ReLU\n",
        ">   #### - sigmoid 함수   \n",
        ">   >  실수 값을 취해서 0과 1사이의 값 출력   \n",
        ">   >  gradient vanishing 문제\n",
        ">   > <img src=\"https://t1.daumcdn.net/cfile/tistory/275BAD4F577B669920\" width=\"400px\" height=\"250px\" alt=\"sigmoid\"></img><br/>\n",
        ">   #### - Tanh 함수   \n",
        ">  >   -1과 1 사이의 실수 값 제곱   \n",
        ">  >   gradient exploding 문제\n",
        ">  >   <img src=\"https://mlnotebook.github.io/img/transferFunctions/tanh.png\" width=\"400px\" height=\"250px\" alt=\"tanh function\"></img><br/>\n",
        ">   #### - ReLU   \n",
        ">  >   f(x) = max(0,x)   \n",
        ">  >   음수는 0, 양수는 그대로\n",
        ">  >   <img src=\"https://learnopencv.com/wp-content/uploads/2017/10/relu-activation-function-1.png\" width=\"400px\" height=\"250px\" alt=\"tanh function\"></img><br/>\n",
        ">  >   - gradient descent의 속도가 빨라 올바른 W 빠르게 찾는다.\n",
        ">  >   - 단순히 임계값만 정해 계산 비용이 저렴(sigmoid, tanh도)\n",
        ">  >   - 역전파(backward propagation)을 수행하는 동안 큰 기울기가 전달되면 반응이 없는 경우 종종 발생 -> learning rate 선택하여 제어\n",
        "\n",
        "- learning rate: parameter에 대한 변경 비율\n",
        "- pytorch에서 모든 네트워크는 nn.Moduel을 서브클래싱하는 클래스들로 구현, init, foward를 구현해야 함\n",
        "  - init: 모든 레이어 초기화(생성자 역할)\n",
        "  - forward: init애서 초기화한 레이어들로 입력 데이터를 전달하고 최종 출력을 반환\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfD0lOjOmWDP"
      },
      "source": [
        "class MyFirstNetwork(nn.Module):    # 부모클래스의 이름을 인수로 전달하여 서브클래스 생성\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MyFirstNetwork,self).__init__() # super: 자식클래스의 인수를 부모클래스(nn.Module)로 전달\n",
        "        self.layer1 = nn.Linear(input_size,hidden_size) \n",
        "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
        "    def __forward__(self,input): \n",
        "        out = self.layer1(input) \n",
        "        out = nn.ReLU(out)\n",
        "        out = self.layer2(out) \n",
        "        return out\n",
        "\n",
        "my_network = MyFirstNetwork(input_size = 3, hidden_size = 2, output_size = 1)       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCjo8VH7m5Ne"
      },
      "source": [
        "---\n",
        "#### loss 함수\n",
        "gradient descent는 일반적으로 스칼라 값을 받아들이기 때문에, loss 함수는 스칼라 값을 생성해야 함 -> 여러 loss를 하나의 스칼라 값으로 합침\n",
        ">   #### - MSE(Mean Square Error): 평균 제곱 오차\n",
        ">   - 회귀 문제를 위한 손실함수\n",
        "\n",
        "```python\n",
        "loss = nn.MSELoss()\n",
        "input = Variable(torch.randn(3, 5), requires_grad=True) \n",
        "target = Variable(torch.randn(3, 5))\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "```\n",
        ">   #### - cross-entropy: 교차 엔트로피\n",
        ">   - 다중 클래스 분류 문제를 위해 사용되는 손실 함수\n",
        ">   - softmax layer와 같이, 더하면 1이 되는 확률 값을 예측하는 분류 네트워크의 loss 계산\n",
        ">   - 예측된 확률이 실제 확률을 벗어날 때 loss 증가\n",
        " \n",
        " ```python\n",
        " def cross_entropy(true_label, prediction):\n",
        "    if true_label == 1:\n",
        "        return -log(prediction)\n",
        "    else:\n",
        "        return -log(1 - prediction)\n",
        "```\n",
        "```python\n",
        "loss = nn.CrossEntropyLoss()\n",
        "input = Variable(torch.randn(3, 5), requires_grad=True) \n",
        "target = Variable(torch.LongTensor(3).random_(5)) \n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "```\n",
        "\n",
        "#### Optimizer(최적화기)\n",
        "  - ex) ASGD, Adadelta, Adagrad, Adam, Adamax, LBFGS, RMSprop, SGD, SparseAdam   \n",
        "  - SGD optimizer(학습 가능한 모든 parameters, learning rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJJMb4Mw1HZg"
      },
      "source": [
        "optimizer = torch.optim.SGD(my_network.parameters(), lr = 0.01)\n",
        "for input, target in torch.utils.data.Dataset:\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwCo4h0x2tEI"
      },
      "source": [
        "## 딥러닝을 이용한 이미지 분류\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwS2hIOn3OdI"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "from torch import optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import time\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VonIWrvR4O1H"
      },
      "source": [
        "- 이미지 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohnb8cJfEsTU"
      },
      "source": [
        "def imshow(inp):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMXIExadE3AE",
        "outputId": "62c6fb2c-cb95-4e53-d336-afe6c8d7fd40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUwqqKFxOkND"
      },
      "source": [
        "path= 'content/gdrive/MyDrive/Dog-Cat-Classifier'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlbryHM3E5_E",
        "outputId": "76c583ae-7954-461d-fe6d-2b77eee7c8a7"
      },
      "source": [
        "cat_files = [f for f in glob.glob('/content/gdrive/MyDrive/Dog-Cat-Classifier/Data/Train_Data/cat/*.jpg')]\n",
        "dog_files = [f for f in glob.glob('/content/gdrive/MyDrive/Dog-Cat-Classifier/Data/Train_Data/dog/*.jpg')]\n",
        "files = dog_files + cat_files\n",
        "print(f'Total no of images {len(files)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of images 1399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLFw-QWJ30NZ"
      },
      "source": [
        "- test dataset(검증데이터셋)을 생성하는데 사용하는 셔플된 인덱스 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY0zK9xH4Xwf"
      },
      "source": [
        "- train imgs, test imgs를 저장할 test directory 생성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAks2vK2Luf7"
      },
      "source": [
        "<br/>\n",
        "\n",
        "---\n",
        "* 코드: <https://github.com/PacktPublishing/Deep-Learning-with-PyTorch-1.x/blob/master/Chapter03/Chapter03a.ipynb>"
      ]
    }
  ]
}
