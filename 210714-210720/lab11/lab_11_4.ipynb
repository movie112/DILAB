{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_11_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6lG+XQ6ElESD5hvucdY6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/lab_11_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD_JpTWots7d"
      },
      "source": [
        "# Lab_11_4: Time Series\n",
        "## contents\n",
        "- time series data\n",
        "- apply RNN\n",
        "  - Many-to-one\n",
        "  - data reading\n",
        "  - neural net setting\n",
        "  - training & evaluation\n",
        "- exercise\n",
        "---\n",
        "## time series data\n",
        "- 일정한 시간 간격으로 배치된 data\n",
        "\n",
        "## apply RNN\n",
        "### 1. Many-to-one\n",
        "example: 7일간 data로 다음 날 종가 예측하는 모델\n",
        "- 전제: 8일차의 종가를 예측하기 위해서 그 전 일주일을 보면 될 것이다.\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchmN6B%2Fbtq0UcFqOkk%2F1SERgahinWKGlblZw2DyH0%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "\n",
        "> 1. dim=5인 vector가 첫 날input으로 들어가서 cell에서 처리된 정보 다음 cell로 전달\n",
        "> 2. 2일차는 input + 전날 처리된 정보를 입력받아 cell에서 처리하고 다음 cell로 전달   \n",
        "> ...\n",
        "> 3. 7번 data 유통하고 마지막에 output으로 8일 종가 예측\n",
        "</br>\n",
        "\n",
        "- 8일차 종가: dim=1 짜리 vector\n",
        "- 바로 8일차 종가 처리한다면 매 단계 hidden state도 dim=1\n",
        "  - model 부담 -> 분산 1. 데이터 유통단계(hidden state) 2. label 맞추는 단계\n",
        "  - 출력 단계에서는 FC를 연결해서 이 output이 종가 맞추도록 구성\n",
        "\n",
        "### 2. data reading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgyjXKGKyiRz"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Random seed to make results deterministic and reproducible\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# hyper parameters\n",
        "seq_length = 7    # 일 수\n",
        "data_dim = 5      # 5개의 dim: 시가, 최고가, 최저가, 거래량, 종가\n",
        "hidden_dim = 10\n",
        "output_dim = 1    # 종가의 dim\n",
        "learning_rate = 0.01\n",
        "iterations = 500\n",
        "\n",
        "\n",
        "# load data\n",
        "xy = np.loadtxt(\"data-02-stock_daily.csv\", delimiter=\",\")\n",
        "xy = xy[::-1]  # reverse order, 시간 역순\n",
        "\n",
        "# 70% 는 train set, 나머지는 test set\n",
        "train_size = int(len(xy) * 0.7)\n",
        "train_set = xy[0:train_size]\n",
        "test_set = xy[train_size - seq_length:]\n",
        "\n",
        "# scaling data\n",
        "# 상대값으로 바꾸어 [0,1]로 나타낸다. (차이가 큰 경우 학습의 부담을 줄여주기 위해서)\n",
        "train_set = minmax_scaler(train_set)\n",
        "test_set = minmax_scaler(test_set)\n",
        "\n",
        "# make train-test dataset to input\n",
        "trainX, trainY = build_dataset(train_set, seq_length)\n",
        "testX, testY = build_dataset(test_set, seq_length)\n",
        "\n",
        "\n",
        "trainX_tensor = torch.FloatTensor(trainX)\n",
        "trainY_tensor = torch.FloatTensor(trainY)\n",
        "\n",
        "testX_tensor = torch.FloatTensor(testX)\n",
        "testY_tensor = torch.FloatTensor(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RvKSmDx1Bax"
      },
      "source": [
        "### 3. neural net setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6ZDxZTjtmru"
      },
      "source": [
        "# neural network 선언 \n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = torch.nn.LSTM(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _status = self.rnn(x)\n",
        "        x = self.fc(x[:, -1])\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net(data_dim, hidden_dim, output_dim, 1)\n",
        "\n",
        "# loss & optimizer setting\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru0p1LAy1dlp"
      },
      "source": [
        "### 4. training & evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6lM2TEI1hu0"
      },
      "source": [
        "# start training\n",
        "for i in range(iterations):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(trainX_tensor)\n",
        "    loss = criterion(outputs, trainY_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(i, loss.item())\n",
        "    \n",
        "  \n",
        "plt.plot(testY)\n",
        "plt.plot(net(testX_tensor).data.numpy())\n",
        "plt.legend(['original', 'prediction'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhIJnsOL1t7v"
      },
      "source": [
        "## exercise\n",
        "- implement stock prediction right now?\n",
        "- use more features to improve robustness"
      ]
    }
  ]
}
