{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_11_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxQz6yp1e6gGrG84C9bEjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/lab_11_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keotIDR0xKcX"
      },
      "source": [
        "# Lab_11_2: RNN_hihello/ charseq\n",
        "## contents\n",
        "- 'Hihello' problem\n",
        "  - 예제 진행하기 앞서 정확히 어떤 문제를 풀고자 하는지 설명\n",
        "- Data setting\n",
        "  - One hot encoding\n",
        "  - input output 어떻게 표현되는지  \n",
        "- Cross entropy loss\n",
        "- Code run through\n",
        "---\n",
        "## 'hihello' problem\n",
        "> - 'hihello' 문자열을 예측하는 모델\n",
        ">   - character가 들어오면 다음 char 예측하는 모델\n",
        ">   - 'h'가 들어오면 'i'를 예측, 'i'가 들어오면 'h' 예측\n",
        "\n",
        "## data setting\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FP5fM0%2FbtqC219isUt%2F7OQbPKDKvAaBoB24GnCJk0%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "- __one-hot encoding__\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkRKAq%2FbtqC3qAYiFK%2FyyK63wqTXjCsNV7TXnd2M1%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "  - 다음 문자를 예측하는 모델이기 때문에 one_hot encoding에서 마지막'o'는 제외\n",
        "  - y_data는 처음 문자 'h' 제외\n",
        "\n",
        "> ## cross entropy loss\n",
        "> <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FxRLTH%2FbtqC0JuNiuR%2FkWLLk5KCzK5DcUaHILLcvK%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "> - categorical output 예측에 주로 사용\n",
        ">   - 일반적으로 output을 softmax를 이용하여 확률값으로 해석\n",
        ">   - 확률값을 정답 카테고리에 대해 최대한 올림: CEL(cross entropy loss) 역할\n",
        "> - loss = criterion(모델의 output, 정답label)\n",
        "## code run through\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTWUHb9u2ZpR"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZBDOS7sI9SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38694f6-8b47-49a8-acd2-2d07bd686e4d"
      },
      "source": [
        "# Random seed to make results deterministic and reproducible\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f16d509bcb0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S77a7TTc3NLw"
      },
      "source": [
        "- (1) code run through(hihello)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vJuYGiJ3GpY",
        "outputId": "157fe48b-45dd-487e-9d24-974fd4eddb3f"
      },
      "source": [
        "# make dictionary 데이터 준비 과정(모델 생성 전)\n",
        "char_set = ['h', 'i', 'e', 'l', 'o']  # char list 정의\n",
        "# hyper parameters 정의\n",
        "dic_size = len(char_dic)\n",
        "hidden_size = len(char_dic)   # 다른 숫자여도 상관 없음\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'f': 0, 'o': 1, 'y': 2, ' ': 3, 'a': 4, 'u': 5, 'n': 6, 'i': 7, 'w': 8, 't': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wouk55j3Wgt"
      },
      "source": [
        "# data setting ; one hot encoding을 통해 input data 제작\n",
        "x_data = [[0, 1, 0, 2, 3, 3]]   # char들을 index로 표현한 것\n",
        "x_one_hot = [[[1, 0, 0, 0, 0], \n",
        "              [0, 1, 0, 0, 0], \n",
        "              [0, 0, 1, 0, 0], \n",
        "              [0, 0, 0, 1, 0], \n",
        "              [0, 0, 0, 0, 1]]]\n",
        "y_data = [[1, 0, 2, 3, 3, 4]]   # i h e l l o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MzYnS5f4xE3"
      },
      "source": [
        "# transform as torch tensor variable\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMWR01pJ4250"
      },
      "source": [
        "- (2) code run through(charseq): 데이터 준비과정 일반화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnaZyysS2qUG",
        "outputId": "2913f89a-695d-4b7c-ce85-7ab5b6a11d98"
      },
      "source": [
        "# 어떤 문자열이든 동작\n",
        "sample = \" if you want you\"\n",
        "# make dictionary\n",
        "char_set = list(set(sample))    # set 함수: 중복 제거한 문자 list 생성\n",
        "\n",
        "# 특정 char를 주면 그 index로 알아서 찾아주는 dictionary\n",
        "char_dic = {c: i for i, c in enumerate(char_set)} # enumerate: index, char 함께 가져옴\n",
        "print(char_dic)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'f': 0, 'o': 1, 'y': 2, ' ': 3, 'a': 4, 'u': 5, 'n': 6, 'i': 7, 'w': 8, 't': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMMipLd46Md"
      },
      "source": [
        "# hyper parameters\n",
        "dic_size = len(char_dic)\n",
        "hidden_size = len(char_dic)\n",
        "learning_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFsncBtJ5zOw"
      },
      "source": [
        "# data setting\n",
        "sample_idx = [char_dic[c] for c in sample]    # char_dic으로 index로 변환\n",
        "x_data = [sample_idx[:-1]]\n",
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data]    # np.eye: 단위행렬 만들어줌(one hot encoding)\n",
        "y_data = [sample_idx[1:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frhAkDCi50rF"
      },
      "source": [
        "# transform as torch tensor variable\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW4NMYCy7srL"
      },
      "source": [
        "- RNN 생성, 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IhUBoxJ50m3"
      },
      "source": [
        "# declare RNN\n",
        "rnn = torch.nn.RNN(dic_size, hidden_size, batch_first=True) #true: batch_dim이 가장 앞으로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyy2D-FX7xQ9"
      },
      "source": [
        "# loss & optimizer setting\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RxhOYzs7xju"
      },
      "source": [
        "# start training\n",
        "for i in range(50):\n",
        "    optimizer.zero_grad() # 꼭 해주어야 함: 기존 gradient에 축적 방지\n",
        "    outputs, _status = rnn(X)\n",
        "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))  # shape batch_dim이 앞에 오도록 재배치 -> loss 계산\n",
        "    loss.backward()   # backpropagation -> gradient 계산\n",
        "    optimizer.step()  # update\n",
        "\n",
        "    # 실제 모델이 어떻게 예측했는지 확인하는 코드\n",
        "    result = outputs.data.numpy().argmax(axis=2) # argmax:어떤 char가 가장 가능성있는지에 대한 숫자 중 가장 큰 숫자가 있는 index를 가져옴\n",
        "    result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "    print(i, \"loss: \", loss.item(), \"prediction: \", result, \"true Y: \", y_data, \"prediction str: \", result_str)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
