{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_11_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnmqUsoiqTGXqjXgOtxedo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/lab_11_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa1rBSgGPyc3"
      },
      "source": [
        "# Lab_11_3: longseq\n",
        "## contents\n",
        "- longseq introduce\n",
        "  - 'hihello', charseq 와는 어떻게 다른지\n",
        "- 긴 문장에서 sequence dataset 만들기(fixed size)\n",
        "- adding FC layer and stacking RNN\n",
        "- code run through\n",
        "---\n",
        "## longseq introduce\n",
        "- 'hihello', charseq는 짧은 문장이라 문장 전체를 하나의 sample로 보고 진행\n",
        "- 실제로 쓸모있는 RNN을 만드려면 긴 문장 dataset 필요\n",
        "  - 아주 긴 문장을 하나의 input으로 사용할 수 없다.\n",
        "  - longseq에서는 긴 문장을 특정 size로 잘라서 사용\n",
        "\n",
        "## makeing sequence dataset from long sentence\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNa2m9%2Fbtq0MT8SlQj%2FodFKBKQCGkAyVz80Qujsz0%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "- 특정 size의 윈도우를 오른쪽으로 한 칸씩 움직인다.\n",
        "- 한 청크를 input_x로, 한 char만큼 shift한 청크를 y로\n",
        "- 반복해서 dataset 만듦\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgtpFm3Fjo1F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2-db2xEi2Sa"
      },
      "source": [
        "# data setting\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "# window를 이동하면서 data를 저장 \n",
        "for i in range(0, len(sentence) - sequence_length):   # 가져올 수 있는 청크의 개수\n",
        "    x_str = sentence[i:i + sequence_length]\n",
        "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
        "    print(i, x_str, '->', y_str)\n",
        "\n",
        "    # character dictionary에 있던 index 값으로 저장\n",
        "    x_data.append([char_dic[c] for c in x_str])  # x string to index\n",
        "    y_data.append([char_dic[c] for c in y_str])  # y string to index\n",
        "\n",
        "# np.eye를 통해 one-hot vector화\n",
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data]\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nll2XMyYjeRU"
      },
      "source": [
        "## adding FC layer and stacking RNN\n",
        "\n",
        "- 저번에는 단순히 RNN cell 하나만 있는 모델을 다룸\n",
        "- 모델을 더 크게 만드는 방법 다양\n",
        "  \n",
        "<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbpWOVj%2Fbtq0Ojzd8AW%2FrkUjbyTIbN8brkVZJE9b30%2Fimg.png\" width=\"250px\" height=\"300px\"></img>\n",
        "- 이번 시간에는 간단하게 RNN을 stacking 하고 마지막에 FC layer 하나 추가\n",
        "- RNN 두 번 통과한 다음 FC layer 쌓고 output_y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJz_jMbmPsCs"
      },
      "source": [
        "## declare RNN + FC\n",
        "class Net(torch.nn.Module):     # Module을 상속받고 Net class로 정의, 두 가지 메소드(init, forward) 정의\n",
        "   # constructor, 모듈이 내부적으로 어떤 하위 모듈을 쓰는지 정의(rnn, fc)\n",
        "    def __init__(self, input_dim, hidden_dim, layers):    \n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "\n",
        "    # input_x 넣고 어떻게 계산할지 정의    \n",
        "    def forward(self, x):\n",
        "        x, _status = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net(dic_size, hidden_size, 2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q8Pm72arL_T"
      },
      "source": [
        "## code run through"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_B89IXjrIbX"
      },
      "source": [
        "# loss & optimizer setting\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)\n",
        "\n",
        "# start training\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\t# 모델 예측 결과 해석\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        # print(i, j, ''.join([char_set[t] for t in result]), loss.item())\n",
        "       \n",
        "        if j == 0: # 맨 처음에는 sequence length만큼의 문자 가져온다.\n",
        "            predict_str += ''.join([char_set[t] for t in result])\n",
        "       \n",
        "        else: # result에서 마지막에 해당하는 문자열만 추가해준다. 맨 마지막빼고 기존 것과 겹침\n",
        "            predict_str += char_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
