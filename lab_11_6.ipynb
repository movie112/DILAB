{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_11_6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzmG9C2jlztfF9Y1Dzxabk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/lab_11_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVzJLrpjU56l"
      },
      "source": [
        "# Lab_11_6: PackedSequence\n",
        "## contents\n",
        "- examples of sequential data\n",
        "- how do we make a batch with multiple sequence sizes?\n",
        "  - padding method\n",
        "  - packing method\n",
        "- Pytorch library functions\n",
        "  - pad_sequence\n",
        "  - pack_sequence\n",
        "  - pad_packed_sequnce\n",
        "  - pack_padded_sequence\n",
        "---\n",
        "## examples of sequential data\n",
        "- 길이가 미정인 data가 대부분\n",
        "  - text, audio\n",
        "\n",
        "## how do we make a batch with multiple sequence sizes?\n",
        "- char 단위로 구성된 5대 sequential data\n",
        "- size가 다른 seq data를 어떻게 하나의 batch로 만들 수 있을까?\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FczyrVf%2Fbtq0OjTH0QC%2F085j378eROgXH2m09gKNFK%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "### 1, padding method\n",
        "> <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbTTbOF%2Fbtq0PdTffen%2F8TOkh2gK545vidcGIvKhn0%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "> - 최장 seq 길이에 맞춰 문장 뒤에 `<pad>` token 써서 채움\n",
        "> - batch_size * 최장 seq 길이 로 하나의 Tensor로 표현\n",
        "> - 처리 간편, 낭비 발생\n",
        "\n",
        "### 2, packing method\n",
        "> <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FP9Dll%2Fbtq0SkRSX5L%2Fzu4hlTOp3RoMaVeBG7X8xK%2Fimg.png\" width=\"500px\" height=\"300px\"></img>\n",
        "> - seq 길이 정보 저장 방식\n",
        "> - pytorch에서 제대로 동작하려면 길이 내림치순으로 정렬\n",
        "> - padding 보다 효율적, 정렬 부담, padding 보다 구현 복잡 \n",
        "\n",
        "## Pytorch library functions\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb5reZs%2Fbtq0NvGRTTQ%2FCEfbOl8u9CjaDQB6pKZ0I1%2Fimg.png\" width=\"500px\" height=\"300px\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xvwFRWeU4gp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}