{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab10_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMoqhXjpd94PaXYA1Wt3ynp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/lab10_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__BfKOX30fC"
      },
      "source": [
        "# Lab_10_2: mnist_cnn\n",
        "## contents   \n",
        "- MNIST에 CNN 적용\n",
        "---\n",
        "## 학습단계\n",
        "1. 라이브러리 가져오기 (torch, torchvision, matplotlib)\n",
        "2. GPU 사용 설정하고 random value 위한 seed 설정\n",
        "3. 학습에 사용되는 parameter 설정(learning_rate, training_epochs, batch_size 등)\n",
        "4. 데이터셋을 가져오고 (학습에 쓰기 편하게) loader 만들기\n",
        "5. 학습 모델 만들기(class CNN(torch.nn.Module))\n",
        "6. Loss function(Criterion)을 선택하고 최적화 도구 선택(optimizer)\n",
        "7. 모델 학습 및 loss check(Criterion의 output)\n",
        "8. 학습된 모델의 성능 확인   \n",
        "---\n",
        "<img src=\"https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyMTAyMDhfMjA2%2FMDAxNjEyNzYwNDI2NjM4.mhRsILGHQpiS6ivDgzN393wkSB5ANcSS0cHGxL9C1Kwg.oPHRyahmJEpcXXDBNovpdopT_K5XXGTLxXlG3o5ILjAg.PNG.chai1226%2Fimage.png&type=sc960_832\" width=\"500px\" height=\"300px\"></img>\n",
        "- 1 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLUBy-KO7hQJ"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbgU7b7h7zAG"
      },
      "source": [
        "- 2 GPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozrEzqG21pe"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)    # ramdom value 설정\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjwUDhUs8D8n"
      },
      "source": [
        "- 3 parameter 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6jXLfJ18Inz"
      },
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiYO-jIJ8LUL"
      },
      "source": [
        "- 4  MNIST dataset 가져오고 loader 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADcuCv-U8R7z"
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,   # False여야 test set 들어옴\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtRbl_H38yxY"
      },
      "source": [
        "- 5 학습 모델 생성 CNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIJOfYVB8y7s"
      },
      "source": [
        "# CNN Model (2 conv layers)\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):   # 초기함수\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # Final FC 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)    # input xrk layter1을 통과하고 나온 값->out\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC, b_s 만큼 펼치고 1줄로\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodCaBVE9ojA"
      },
      "source": [
        "# instantiate CNN model\n",
        "model = CNN().to(device)  #device: CUDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjDZSBI79qWo"
      },
      "source": [
        "- 6 loss 함수, optimizer 도구 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flU4bb1k9wYb"
      },
      "source": [
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmwMGX8W90T-"
      },
      "source": [
        "- 7 model 학습 및 loss check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf9iOSJ_9zvl",
        "outputId": "6b480684-6ebf-4eef-815d-c8750a49c906"
      },
      "source": [
        "# train my model\n",
        "total_batch = len(data_loader)\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0    # loss 담는 변수\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))   # 한 epoch 끝나면 Epoch에 대해 cost 계산\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning started. It takes sometime.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch:    1] cost = 0.228720948\n",
            "[Epoch:    2] cost = 0.0667807683\n",
            "[Epoch:    3] cost = 0.0490398295\n",
            "[Epoch:    4] cost = 0.0399324112\n",
            "[Epoch:    5] cost = 0.0331932344\n",
            "[Epoch:    6] cost = 0.0275703426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eswKNOrL-Hcr"
      },
      "source": [
        "- 8 성능 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUIK0EOI-Jpn"
      },
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad(): # 학습 안해\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}