{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_ch1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHAKsFJCgDLCNx8erFR/tR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie112/INU-DILAB/blob/main/NLP_pytorch/NLP_ch1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6gfFaQzRFPw"
      },
      "source": [
        "# 파이토치로 배우는 자연어 처리: ch1\n",
        "## 1. 소개   \n",
        "1.1 지도학습   \n",
        "1.2 샘플과 타깃의 인코딩   \n",
        "  - 원-핫 인코딩, TF 표현, TF-IDF 표현, 타깃 인코딩   \n",
        "\n",
        "1.3 계산 그래프   \n",
        "1.4 파이토치 기초\n",
        "  - 파이토치 설치, 텐서 만들기, 텐서 타입과 크기, 텐서, 텐서와 계산 그래프, CUDA 텐서\n",
        "---\n",
        "## 학습목표\n",
        "- 지도 학습 이해, 용어 인지, 기초 개념 정립\n",
        "- 머신러닝 문제에 맞도록 입력을 인코딩하는 방법\n",
        "- 계산 그래프 이해\n",
        "- 파이토치 기본 숙달\n",
        "---\n",
        "## 1.1 지도학습\n",
        "- observation에 대응하는 target의 정답을 제공하는 방식   \n",
        "주요 개념   \n",
        "- 샘플: 에측에 사용하는 아이템, 입력, x\n",
        "- target: 샘플에 상응하는 레이블, 예측되는 대상, 정답, y\n",
        "- 모델: 수학식이나 샘플x를 받아 target label값을 예측하는 함수\n",
        "- parameter: 가중치, 모델을 규정\n",
        "- 예측: 모델이 추축하는 target값, 추정, hat 표기\n",
        "- 손실함수: 훈련 데이터에 대한 예측이 target과 얼마나 차이 나는지 비교하는 함수, L\n",
        "\n",
        "#### gradient descent\n",
        "- gradient descent: data set에서 손실함수를 최소화하는 parameter 값 찾기, 전통적인 gradient descent는 적용이 어렵고 비용 큼\n",
        "- stochastic gradient descent(SGD)\n",
        "  - 확률적 경사 하강법, data point를 하나 또는 일부 랜덤하게 선택하여 gradient 계산,\n",
        "  - minibatch SGD: pure SGD 여러 개 사용하는 방법\n",
        "  - pure SGD: updata레 잡음이 많아 수렴이 매우 느림\n",
        "  - backpropagation: 역전파, parameter를 반복적으로 update하는 과정\n",
        "    - 각 단계(epoch)는 정방향계산(foward pass), 역방향 계산(backward padd) 구성\n",
        "    - foward: 현재 parameter 값으로 입력을 평가해 손실함수 계산\n",
        "    - backward: 손실의 gradient를 사용해 parameter update\n",
        "---\n",
        "## 1.2 샘플과 타깃의 인코딩\n",
        "### 1.2.1. one-hot representation\n",
        "0 벡터에서 시작해 문장이나 문서에 등장하는 단어에 상응하는 원소를 1로 설정   \n",
        "example) Time files like an arrow. / Fruit flies like a banana.\n",
        "- 문장을 token으로 나누고 구두점을 무시하고 모두 소문자로 바꾸면 vocabulary의 크기는 8이 된다.\n",
        "- { time, fruit, flies, like, a , an, arrow, banana}\n",
        "- \"like a banana\"의 one-hot 표현은 3X8 행렬 \n",
        "\n",
        "### 1.2.2 TF 표현\n",
        "단순히 소속 단어의 one-hot representation을 합해 만듦   \n",
        "example) Fruit flies like time flies a fruit -> [1, 2, 2, 1, 1, 0, 0, 0] 각 원소는 해당 단어가 문장에 등장하는 횟수\n",
        "\n",
        "### 1.2.3 TF-IDF 표현\n",
        "- TF는 등장 획수에 비례하여 단어에 가중치 부여, 흔한 단어에는 문서 특징이 담겨 있지 않음\n",
        "- inverse-document-frequency(IDF): 흔한 토큰의 점수를 낮추고 드문 토큰의 점수를 높임\n",
        "- 딥러닝의 목적은 표현 합습이므로 보통 TF-IDF 같이 경험적인 방법으로 입력을 인코딩하지 않는다. \n",
        "\n",
        "### 1.2.4 타깃 인코딩\n",
        "많은 NLP 작업은 범주형 레이블을 사용\n",
        "- 모델은 고정된 한 세트의 레이블 중 하나를 예측해야 함 이를 인코딩할 때는 레이블마다 고유한 인덱스를 부여하는 방법을 가정 많이 사용, 하지만 이런 간단한 표현은 출력 레이블 수가 너무 커지면 문제가 된다.ex) 언어 모델링: 이전 단어로 다음 단어 예측\n",
        "---\n",
        "## 1.3 계산 그래프\n",
        "---\n",
        "## 1.4 파이토치 기초\n",
        "차원을 지정해서 텐서 랜덤 초기화\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXNY7FXMRB2h"
      },
      "source": [
        "import torch\n",
        "t = torch.Tensor(2, 3)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx41usU2jKTU"
      },
      "source": [
        "[0, 1) 범위의 균등 분포에서 샘플링한 값으로 랜덤하게 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmObsP3kjWjy"
      },
      "source": [
        "t = torch.rand(2, 3)  # 균등 분포\n",
        "t = torch.randn(2, 3) # 표준 균등 분포"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwFJ-mHwjjSF"
      },
      "source": [
        "0 또는 1 또는 특정 값으로 채운 텐서"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9am8Gx8QkCWH"
      },
      "source": [
        "t = torch.zeros(2, 3)\n",
        "t = torch.ones(2, 3)\n",
        "t.fill_(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMvYmzO-kT-T"
      },
      "source": [
        "리스트로 텐서 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3aZyhHTkXVf"
      },
      "source": [
        "t = torch.Tensor([1, 2, 3], \n",
        "                 [4, 5, 6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfHhChDwk3Xl"
      },
      "source": [
        "numpy로 텐서 만들고 초기화\n",
        "- numpy 배열은 tensor type이 FloatTensor가 아니라 DoubleTensor가 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCDOye41lGmF"
      },
      "source": [
        "import numpy as np\n",
        "npy = np.random.rand(2, 3)\n",
        "t = torch.from_numpy(npy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsYjLBb9lSwh"
      },
      "source": [
        "인덱싱, 슬라이싱, 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpn8S-ypl1dt",
        "outputId": "3ab6cb8c-e1fe-4716-fff0-d06cf7105487"
      },
      "source": [
        "x = torch.arange(6).view(2, 3)\n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbM-3-LDm3fR",
        "outputId": "af49dbd7-9ecf-499a-b8de-8acede03863b"
      },
      "source": [
        "print(x[:1, :2])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv54Usqsm3JA"
      },
      "source": [
        ""
      ]
    }
  ]
}